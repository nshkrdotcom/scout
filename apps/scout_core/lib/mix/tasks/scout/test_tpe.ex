defmodule Mix.Tasks.Scout.TestTpe do
  use Mix.Task

  @shortdoc "Test improved TPE implementation"

  @moduledoc """
  Tests the improved TPE implementation with aligned parameters.
  This validates that the dogfooding-driven fixes work.

  ## Usage

      mix scout.test_tpe
  """

  def run(_args) do
    Mix.Task.run("app.start")

    IO.puts("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                   IMPROVED TPE VALIDATION TEST                    â•‘
    â•‘               (Testing Dogfooding-Driven Fixes)                   â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # Test 1: ML hyperparameters
    ml_result =
      run_tpe_test(
        "ML Hyperparameters",
        &ml_objective/1,
        &ml_search_space/1,
        :maximize,
        30
      )

    # Test 2: Rastrigin benchmark  
    rastrigin_result =
      run_tpe_test(
        "Rastrigin Benchmark",
        &rastrigin_objective/1,
        &rastrigin_search_space/1,
        :minimize,
        50
      )

    # Compare with previous results
    IO.puts("\nğŸ“Š PERFORMANCE COMPARISON:")
    IO.puts(String.duplicate("â”", 67))

    IO.puts("\nML Hyperparameters:")
    IO.puts("  Before fixes: 0.510")
    IO.puts("  After fixes:  #{Float.round(ml_result.best_value, 6)}")
    IO.puts("  Optuna:       0.733")

    ml_improvement = (ml_result.best_value - 0.510) / 0.510 * 100
    IO.puts("  Improvement:  #{Float.round(ml_improvement, 1)}%")

    IO.puts("\nRastrigin Benchmark:")
    IO.puts("  Before fixes: 6.180")
    IO.puts("  After fixes:  #{Float.round(rastrigin_result.best_value, 6)}")
    IO.puts("  Optuna:       2.280")

    rastrigin_improvement = (6.180 - rastrigin_result.best_value) / 6.180 * 100
    IO.puts("  Improvement:  #{Float.round(rastrigin_improvement, 1)}%")

    IO.puts("\nğŸ¯ KEY IMPROVEMENTS APPLIED:")
    IO.puts("âœ… Gamma: 0.15 â†’ 0.25 (closer to Optuna's 0.5)")
    IO.puts("âœ… Min obs: 20 â†’ 10 (matches Optuna's n_startup_trials)")
    IO.puts("âœ… Integer parameter support added")
    IO.puts("âœ… Scott's rule for KDE bandwidth (1.06 factor)")

    IO.puts("\nğŸ“ˆ PARITY ASSESSMENT:")

    # Calculate final parity
    ml_gap = abs(ml_result.best_value - 0.733) / 0.733 * 100
    rastrigin_gap = abs(rastrigin_result.best_value - 2.280) / 2.280 * 100
    avg_gap = (ml_gap + rastrigin_gap) / 2

    IO.puts("  ML gap:        #{Float.round(ml_gap, 1)}%")
    IO.puts("  Rastrigin gap: #{Float.round(rastrigin_gap, 1)}%")
    IO.puts("  Average gap:   #{Float.round(avg_gap, 1)}%")

    if avg_gap < 30 do
      IO.puts("\nâœ… EXCELLENT: Scout TPE now has strong parity with Optuna!")
    else
      IO.puts("\nâš ï¸  Still some gaps, but significant improvement achieved")
    end
  end

  defp ml_objective(params) do
    learning_rate = params[:learning_rate] || 0.1
    max_depth = params[:max_depth] || 6
    n_estimators = params[:n_estimators] || 100
    subsample = params[:subsample] || 1.0
    colsample_bytree = params[:colsample_bytree] || 1.0

    # Identical scoring to optuna_baseline.py
    lr_score = -abs(:math.log10(learning_rate) + 1.0)
    depth_score = -abs(max_depth - 6) * 0.05
    n_est_score = -abs(n_estimators - 100) * 0.001
    subsample_score = -abs(subsample - 0.8) * 0.1
    colsample_score = -abs(colsample_bytree - 0.8) * 0.1

    accuracy = 0.8 + lr_score + depth_score + n_est_score + subsample_score + colsample_score
    max(0.0, min(1.0, accuracy))
  end

  defp ml_search_space(_) do
    %{
      learning_rate: {:log_uniform, 0.001, 0.3},
      max_depth: {:int, 3, 10},
      n_estimators: {:int, 50, 300},
      subsample: {:uniform, 0.5, 1.0},
      colsample_bytree: {:uniform, 0.5, 1.0}
    }
  end

  defp rastrigin_objective(params) do
    x = params[:x] || 0.0
    y = params[:y] || 0.0

    20 + x * x - 10 * :math.cos(2 * :math.pi() * x) + y * y - 10 * :math.cos(2 * :math.pi() * y)
  end

  defp rastrigin_search_space(_) do
    %{
      x: {:uniform, -5.12, 5.12},
      y: {:uniform, -5.12, 5.12}
    }
  end

  defp simple_trial(id, params, score, status \\ :succeeded) do
    %{
      id: id,
      study_id: "test",
      params: params,
      bracket: 0,
      score: score,
      status: status
    }
  end

  defp run_tpe_test(test_name, objective_func, search_space_func, goal, n_trials) do
    IO.puts("\nğŸ”¬ Testing Improved TPE: #{test_name}")
    IO.puts("  " <> String.duplicate("â”€", 40))

    # Use improved TPE parameters (defaults are now better)
    tpe_opts = %{goal: goal}

    state = Scout.Sampler.TPE.init(tpe_opts)

    # Run optimization
    {history, best_value, _best_params, _final_state} =
      Enum.reduce(1..n_trials, {[], nil, %{}, state}, fn i, {hist, best_val, best_p, state_acc} ->
        # Get next parameters from TPE
        {params, new_state} = Scout.Sampler.TPE.next(search_space_func, i, hist, state_acc)
        score = objective_func.(params)

        # Create trial
        trial = simple_trial("trial-#{i}", params, score)

        # Update history
        new_history = hist ++ [trial]

        # Update best
        {new_best_val, new_best_params} =
          case goal do
            :maximize ->
              if best_val == nil or score > best_val do
                {score, params}
              else
                {best_val, best_p}
              end

            :minimize ->
              if best_val == nil or score < best_val do
                {score, params}
              else
                {best_val, best_p}
              end
          end

        # Update state for next iteration
        next_state = new_state

        # Show progress
        if rem(i, 10) == 0 do
          IO.write(".")
        end

        # Return accumulated values
        {new_history, new_best_val, new_best_params, next_state}
      end)

    IO.puts("")
    IO.puts("  Best value: #{Float.round(best_value, 6)}")
    IO.puts("  Trials evaluated: #{length(history)}")

    %{
      test_name: test_name,
      best_value: best_value,
      n_trials: n_trials
    }
  end
end
